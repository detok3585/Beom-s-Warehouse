{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorFlowSample08.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"qWLK1fNVOwuN","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow.examples.tutorials.mnist.input_data as input_data\n","def train_and_test_data_mnist():\n","\n","    db_path = 'C:\\MLTest\\MNIST'  # TODO: you db path\n","    mnist = input_data.read_data_sets(db_path, one_hot=True)\n","    print('Training data size: ' + str(mnist.train.images.shape))\n","    print('Test data size: ' + str(mnist.test.images.shape))\n","    x_train = mnist.train.images # 55000x784\n","    y_train = mnist.train.labels # 55000x10\n","    x_test = mnist.test.images\n","    y_test = mnist.test.labels\n","    return x_train, y_train, x_test, y_test\n","\n","def create_placeholders(x_shape, y_shape):\n","    x = tf.placeholder(tf.float32, shape=[None, x_shape]) # 784 for mnist\n","    y = tf.placeholder(tf.float32, shape=[None, y_shape]) # 10 for mnist\n","    return x, y\n","\n","def init_parameters(n_chnls_img, n_chnls_conv1, n_chnls_conv2):\n","\n","    w1 = tf.get_variable('w1', shape=[5, 5, n_chnls_img, n_chnls_conv1],\n","                         initializer=tf.contrib.layers.xavier_initializer(seed=0))\n","    w2 = tf.get_variable('w2', shape=[3, 3, n_chnls_conv1, n_chnls_conv2],\n","                         initializer=tf.contrib.layers.xavier_initializer(seed=0))\n","    params = {'w1': w1,\n","              'w2': w2}\n","    return params\n","\n","\n","def forward_propagation(x, params):\n","    x = tf.reshape(x, shape=[-1,28,28,1])   # reshape to 28x28. all at once\n","    w1 = params['w1']\n","    w2 = params['w2']\n","\n","    conv1 = tf.nn.conv2d(x, w1, strides=[1,1,1,1], padding='SAME')\n","    relu1 = tf.nn.relu(conv1)\n","    pool1 = tf.nn.max_pool(relu1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n","\n","    conv2 = tf.nn.conv2d(pool1, w2, strides=[1,1,1,1], padding='SAME')\n","    relu2 = tf.nn.relu(conv2)\n","    pool2 = tf.nn.max_pool(relu2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n","    # flatten the pool2 to feed into the fully connected layer\n","    pool2 = tf.contrib.layers.flatten(pool2)\n","\n","    fc1 = tf.contrib.layers.fully_connected(pool2, num_outputs=1024)\n","    fc1 = tf.nn.dropout(fc1, keep_prob=0.75)\n","    fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=10, activation_fn=None)\n","    return fc2\n","\n","\n","def compute_cost(fc_out, y):\n","    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc_out, labels=y))\n","    return cost\n","\n","\n","def back_propagation(cost, learning_rate):\n","    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n","    return optimizer\n","\n","\n","def driver_function(x_train, y_train, x_test, y_test, hyper_parameters):\n","    # unpack the network hyper params\n","    learning_rate = hyper_parameters['learning_rate']\n","    n_epochs = hyper_parameters['n_epochs']\n","    batch_size = hyper_parameters['batch_size']\n","    display_step = hyper_parameters['display_step']\n","    n_chnls_img = hyper_parameters['n_chnls_img']\n","    n_chnls_conv1 = hyper_parameters['n_chnls_conv1']\n","    n_chnls_conv2 = hyper_parameters['n_chnls_conv2']\n","\n","    tf.reset_default_graph()\n","    tf.set_random_seed(seed=1)\n","    m, x_shape = x_train.shape  # m is the total number of samples\n","    _, y_shape = y_train.shape\n","    x, y = create_placeholders(x_shape, y_shape)\n","    params = init_parameters(n_chnls_img, n_chnls_conv1, n_chnls_conv2)\n","    model = forward_propagation(x, params)\n","    cost = compute_cost(model, y)\n","    optimizer = back_propagation(cost, learning_rate)\n","    all_costs = []              # save errors from all epochs. to plot\n","\n","    init = tf.global_variables_initializer()\n","    with tf.Session() as sess:\n","        sess.run(init)\n","        for epoch in range(n_epochs):\n","            num_batch = int(m / batch_size)\n","            count = 0\n","            batch_cost = 0\n","            for nb in range(num_batch):\n","                train_data = x_train[count:count+batch_size]\n","                train_lebels = y_train[count:count+batch_size]\n","                _, tmp_cost = sess.run([optimizer, cost],\n","                                       feed_dict={x:train_data, y:train_lebels})\n","                batch_cost += tmp_cost\n","                count += batch_size\n","            all_costs.append(batch_cost/num_batch)\n","\n","            if epoch % display_step == 0:\n","                print('epoch %d:,  minibatch loss: %f' %(epoch, batch_cost/num_batch))\n","        print('optimization done ...')\n","\n","        # evaluate the model now on the Test Set. images network have not seen so far\n","        correct_pred = tf.equal(tf.arg_max(model, 1), tf.arg_max(y, 1))\n","        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","        train_accuracy = accuracy.eval({x: x_train, y:y_train})\n","        test_accuracy = accuracy.eval({x: x_test, y: y_test})\n","\n","    return train_accuracy, test_accuracy, params, all_costs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9t64j7aROwuQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1128},"outputId":"c3368903-0e3a-4ae0-e73c-f9bde5288a4a"},"cell_type":"code","source":["learning_rate = 0.001\n","n_epochs = 10         # total number of iterations of training\n","batch_size = 100      # or min-batch size\n","display_step = 1      # show prediction errors after each of this many steps\n","\n","n_chnls_img = 1       # mnist images are one channel. 3 for rgb images\n","n_chnls_conv1 = 32    # just a choice\n","n_chnls_conv2 = 64\n","\n","# pack them in a dictionary. sending too many function argument looks clutter\n","hyper_parameters = {'learning_rate': learning_rate, 'n_epochs': n_epochs,\n","                        'batch_size': batch_size, 'display_step': display_step,\n","                        'n_chnls_img': n_chnls_img, 'n_chnls_conv1': n_chnls_conv1,\n","                        'n_chnls_conv2': n_chnls_conv2}\n","\n","x_train, y_train, x_test, y_test = train_and_test_data_mnist()\n","#plt.imshow(x_train[2018, :].reshape((28, 28)), cmap='gray') # look at an image\n","train_acc, test_acc, _, all_costs = driver_function(x_train, y_train,\n","                                                        x_test, y_test,\n","                                                        hyper_parameters)\n","# show the training errors\n","plt.plot(np.squeeze(all_costs))\n","plt.xlabel('iterations');plt.ylabel('cost')\n","plt.title('Learning rate %f' %learning_rate)\n","plt.show()\n","\n","#print('Train accuray: %f' %train_acc)\n","#print('Test accuracy: %f' %test_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-1-db0a9a81de93>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting C:\\MLTest\\MNIST/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting C:\\MLTest\\MNIST/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting C:\\MLTest\\MNIST/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting C:\\MLTest\\MNIST/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","Training data size: (55000, 784)\n","Test data size: (10000, 784)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From <ipython-input-1-db0a9a81de93>:49: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From <ipython-input-1-db0a9a81de93>:55: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","epoch 0:,  minibatch loss: 0.161993\n","epoch 1:,  minibatch loss: 0.046995\n","epoch 2:,  minibatch loss: 0.029847\n","epoch 3:,  minibatch loss: 0.022192\n","epoch 4:,  minibatch loss: 0.018277\n","epoch 5:,  minibatch loss: 0.013763\n","epoch 6:,  minibatch loss: 0.012781\n","epoch 7:,  minibatch loss: 0.009959\n","epoch 8:,  minibatch loss: 0.008739\n","epoch 9:,  minibatch loss: 0.008340\n","optimization done ...\n","WARNING:tensorflow:From <ipython-input-1-db0a9a81de93>:106: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.math.argmax` instead\n"],"name":"stdout"}]},{"metadata":{"id":"meTiGMjXOwuS","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}